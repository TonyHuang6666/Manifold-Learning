{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库函数\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigs\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPP算法\n",
    "\n",
    "Pi = 3.14159265358979323846\n",
    "\n",
    "def knn_graph(Data, method, k):\n",
    "    \"\"\"\n",
    "    计算k近邻图\n",
    "\n",
    "    Args:\n",
    "    - Data: 输入数据集的矩阵，每行代表一个样本点\n",
    "    - k: 最近邻的数量\n",
    "\n",
    "    Returns:\n",
    "    - knn_adjacency_matrix: k近邻图的邻接矩阵，W[i, j]表示样本点i和j之间是否相连\n",
    "    \"\"\"\n",
    "    # 获取样本点的数量\n",
    "    n = Data.shape[0]\n",
    "    # 初始化k近邻图的邻接矩阵\n",
    "    knn_adjacency_matrix = np.zeros((n, n))  \n",
    "    # 计算欧式距离矩阵\n",
    "    distances = np.sqrt(np.sum((Data[:, None] - Data) ** 2, axis=2))\n",
    "    if method == 'epsilon':\n",
    "        return knn_adjacency_matrix, distances\n",
    "    # 获取每个样本点的最近邻索引\n",
    "    indices = np.argsort(distances, axis=1)[:, 1:k+1]\n",
    "    # 构建k近邻图的权重矩阵\n",
    "    # 遍历每个样本点的最近邻索引\n",
    "    for i in range(n):\n",
    "        knn_adjacency_matrix[i, indices[i]] = 1\n",
    "        knn_adjacency_matrix[indices[i], i] = 1\n",
    "    return knn_adjacency_matrix, distances\n",
    "\n",
    "# 以每个点到其他所有点的平均值作为每个数据点的平均邻域半径\n",
    "def compute_avg_radius(Data, distances): \n",
    "    n = Data.shape[0] # 数据集的大小\n",
    "    radius = np.zeros(n) # 存储每个数据点的平均邻域半径\n",
    "    for i in range(n): # 计算每个数据点的平均邻域半径\n",
    "        avg_radius = np.mean(distances[i]) # 每个数据点到其他所有点的平均值\n",
    "        radius[i] = avg_radius # 存储每个数据点的平均邻域半径\n",
    "    return radius\n",
    "\n",
    "# 计算k最近邻索引矩阵或epsilon邻接矩阵\n",
    "def compute_neighborhood_matrix(Data, method, k):\n",
    "    n = len(Data)\n",
    "    knn_adjacency_matrix, distances = knn_graph(Data, method, k)\n",
    "    if method == 'knn':\n",
    "        return knn_adjacency_matrix, distances\n",
    "    elif method == 'epsilon':\n",
    "        adjacency_matrix = np.zeros((n, n))\n",
    "        radius = compute_avg_radius(Data, distances)  # 计算每个数据点的邻域半径\n",
    "        for i in range(n):  # 对于数据集中的每个样本点 i\n",
    "            distances = np.sqrt(np.sum((Data[i] - Data) ** 2, axis=1))\n",
    "            neighbors = []\n",
    "            for j in range(n):  # 初始化 neighbors 列表\n",
    "                if (distances[j] <= radius[i]) and (len(neighbors) <= n/2): # 如果样本点 j 在第i个样本点的epsilon邻域内\n",
    "                    neighbors.append(j)\n",
    "            adjacency_matrix[i, neighbors] = 1\n",
    "            adjacency_matrix[neighbors, i] = 1\n",
    "        return adjacency_matrix, distances\n",
    "\n",
    "# 构建基于热核方法的权重矩阵\n",
    "def construct_weight_matrix(Data, method, k, t):\n",
    "    n = len(Data)\n",
    "    Weight_matrix = np.zeros((n, n))\n",
    "    adjacency_matrix, distances = compute_neighborhood_matrix(Data, method, k)\n",
    "    if method == 'knn':\n",
    "        # 计算相似度矩阵\n",
    "        similarity_matrix = np.exp(-distances ** 2 / t)\n",
    "        # 将相似度矩阵按照邻接矩阵进行筛选，得到需要设置权重的位置\n",
    "        i_indices, j_indices = np.where(adjacency_matrix == 1)\n",
    "        # 设置权重\n",
    "        Weight_matrix[i_indices, j_indices] = similarity_matrix[i_indices, j_indices]\n",
    "        Weight_matrix[j_indices, i_indices] = similarity_matrix[i_indices, j_indices]  # 对称矩阵\n",
    "    elif method == 'epsilon':\n",
    "        for i in range(n):  # 对于数据集中的每个样本点 i\n",
    "            for j in range(n):  # 对于数据集中的每个样本点 j\n",
    "                if adjacency_matrix[i, j] == 1:  # 如果样本点 j 在第i个样本点的epsilon邻域内\n",
    "                    distance = np.linalg.norm(Data[i] - Data[j])  # 计算样本点 i 和 j 之间的距离（欧式距离）\n",
    "                    Weight_matrix[i, j] = np.exp(-distance ** 2 / t) # 使用热核方法计算权重\n",
    "                    Weight_matrix[j, i] = np.exp(-distance ** 2 / t) # 邻接矩阵为对称矩阵\n",
    "    # 计算全局相似度\n",
    "    '''\n",
    "    修正权重矩阵的原理是利用全局相似度来修正局部相似度得到的权重矩阵，以使得整个权重矩阵更加平滑和连续。\n",
    "    '''\n",
    "    #print('adjacency_matrix:', adjacency_matrix.shape)\n",
    "    #print('Weight_matrix:', Weight_matrix.shape)\n",
    "    Weight_matrix += np.exp(-distances ** 2 / t)\n",
    "    return Weight_matrix  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLDA算法\n",
    "\n",
    "# 计算每个类别的均值矩阵\n",
    "def compute_classes_mean_matrix(train_data, train_labels):\n",
    "    num_classes = len(np.unique(train_labels))  # 类别数量\n",
    "    num_samples_per_class = train_data.shape[0] // num_classes  # 每个类别的样本数\n",
    "    num_features = train_data.shape[1]  # 每个样本的特征维度\n",
    "    \n",
    "    means = np.zeros((num_classes, num_features))  # 存储每个类别的均值矩阵\n",
    "    \n",
    "    for i in range(1, num_classes + 1):  # 遍历每个类别\n",
    "        temp_indices = np.where(train_labels == i)[0]  # 获取当前类别的训练数据索引\n",
    "        temp_sum = np.sum(train_data[temp_indices], axis=0)  # 计算当前类别的特征值总和\n",
    "        means[i-1] = temp_sum / num_samples_per_class  # 计算当前类别的均值\n",
    "        \n",
    "    return means  # 返回每个类别的均值矩阵\n",
    "\n",
    "# 计算所有类别的整体均值矩阵\n",
    "def compute_overall_mean_matrix(classes_means):\n",
    "    overall_mean = np.mean(classes_means, axis=0)  # 计算所有类别的整体均值\n",
    "    return overall_mean.reshape(-1, 1)  # 返回整体均值矩阵（转置）\n",
    "\n",
    "# 计算中心类别矩阵\n",
    "def compute_center_class_matrix(train_data, train_labels, classes_means):\n",
    "    Z = np.zeros_like(train_data)  # 初始化中心类别矩阵\n",
    "    \n",
    "    for i in range(train_data.shape[0]):  # 遍历训练数据\n",
    "        class_index = int(train_labels[i]) - 1  # 获取当前样本所属类别的索引\n",
    "        Z[i] = train_data[i] - classes_means[class_index]  # 计算中心类别矩阵\n",
    "        \n",
    "    return Z  # 返回中心类别矩阵\n",
    "\n",
    "# 计算类间散布矩阵\n",
    "def compute_between_class_scatter_matrix(classes_means, overall_mean):\n",
    "    n = 5  # 训练集与测试集的比例\n",
    "    Sb = np.zeros((classes_means.shape[1], classes_means.shape[1]))  # 初始化类间散布矩阵\n",
    "    for i in range(classes_means.shape[0]):  # 遍历每个类别的均值矩阵\n",
    "        Sb = np.add(Sb, n * ((classes_means[i] - overall_mean) * (classes_means[i] - overall_mean).T))  # 计算类间散布矩阵\n",
    "    return Sb  # 返回类间散布矩阵\n",
    "\n",
    "# 计算类内散布矩阵\n",
    "def compute_class_scatter_matrix(Z):\n",
    "    Sw = np.dot(Z.T, Z)  # 计算类内散布矩阵\n",
    "    return Sw  # 返回类内散布矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowEigenface(eigenfaces):\n",
    "    # 显示前16个特征脸\n",
    "    fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(8, 10))\n",
    "    for i in range(16):\n",
    "        axes[i%4][i//4].imshow(eigenfaces[:, i].reshape(112,92), cmap=\"gray\")\n",
    "    #print(\"显示特征脸\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPP(train_data, train_labels, method, d, k, t):\n",
    "    Data = train_data.T\n",
    "    print('Data形状:', Data.shape)\n",
    "    # Step 1: 计算权重矩阵\n",
    "    weight_matrices = []  # 存储每个类别的权重矩阵\n",
    "    degree_matrices = []  # 存储每个类别的度矩阵\n",
    "    classes_train_data = []  # 存储每个类别的训练数据\n",
    "    for class_label in np.unique(train_labels):\n",
    "        class_indices = np.where(train_labels == class_label)[0]  # 获取当前类别的样本索引\n",
    "        class_train_data = Data[:, class_indices]  # 获取当前类别的样本数据\n",
    "        Weight_matrix = construct_weight_matrix(class_train_data, method, k, t)  # 计算当前类别的权重矩阵\n",
    "        Degree_matrix = np.diag(np.sum(Weight_matrix, axis=1))  # 计算当前类别的度矩阵\n",
    "        weight_matrices.append(Weight_matrix)\n",
    "        degree_matrices.append(Degree_matrix)\n",
    "        classes_train_data.append(class_train_data)\n",
    "\n",
    "    #列表转化为三维矩阵\n",
    "    classes_train_data = np.stack(classes_train_data, axis=2)\n",
    "    weight_matrices = np.stack(weight_matrices, axis=2)\n",
    "    degree_matrices = np.stack(degree_matrices, axis=2)\n",
    "    print('classes_train_data形状:', classes_train_data.shape)\n",
    "    print('weight_matrices 形状:', weight_matrices.shape)\n",
    "    print('degree_matrices 形状:', degree_matrices.shape)\n",
    "\n",
    "    # 按照第三个维度将权重矩阵和度矩阵对角化\n",
    "    diagonal_weight_matrices = np.array([np.diag(weight_matrices[:, :, i]) for i in range(weight_matrices.shape[2])])\n",
    "    diagonal_degree_matrices = np.array([np.diag(degree_matrices[:, :, i]) for i in range(degree_matrices.shape[2])])\n",
    "    print('diagonal_weight_matrices形状:', diagonal_weight_matrices.shape)\n",
    "    print('diagonal_degree_matrices形状:', diagonal_degree_matrices.shape)\n",
    "\n",
    "    #Laplacian_matrices = diagonal_degree_matrices - diagonal_weight_matrices # 计算拉普拉斯矩阵\n",
    "    Laplacian_matrices = degree_matrices - weight_matrices\n",
    "    print('Laplacian_matrices形状:', Laplacian_matrices.shape)\n",
    "    return Laplacian_matrices.T, classes_train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLDA(train_data, train_labels, d):\n",
    "    # 计算每个类别的均值矩阵\n",
    "    classes_means = compute_classes_mean_matrix(train_data, train_labels)\n",
    "    #print('classes_means形状：', classes_means.shape)\n",
    "\n",
    "    # 计算所有类别的整体均值矩阵\n",
    "    overall_mean = compute_overall_mean_matrix(classes_means)\n",
    "    #print('overall_mean形状：', overall_mean.shape)\n",
    "\n",
    "    # 计算中心类别矩阵\n",
    "    #Z = compute_center_class_matrix(train_data, train_labels, classes_means)\n",
    "    #print('Z形状：', Z.shape)\n",
    "\n",
    "    # 计算类间散布矩阵\n",
    "    #Sb = compute_between_class_scatter_matrix(classes_means, overall_mean)\n",
    "    #print('Sb形状：', Sb.shape)\n",
    "\n",
    "    # 计算类内散布矩阵\n",
    "    #Sw = compute_class_scatter_matrix(Z)\n",
    "    #print('Sw形状：', Sw.shape)\n",
    "    \n",
    "    return classes_means.T, overall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DLPP(train_data, train_labels, d, lpp_method, k, t):\n",
    "\n",
    "    # Step 1: 使用MLDA进行特征提取\n",
    "    F, overall_mean = MLDA(train_data, train_labels, d)\n",
    "    print(\"F:\", F.shape)\n",
    "    # Step 2: 使用LPP进行特征提取\n",
    "    L, X = LPP(train_data, train_labels, lpp_method, d, k, t)\n",
    "    print(\"train_data:\", train_data.shape)\n",
    "    # Step 3: 计算权重矩阵B\n",
    "    num_classes = len(np.unique(train_labels))  # 计算训练集中的类别数\n",
    "    B = np.zeros((num_classes, num_classes))  # 初始化权重矩阵B，形状为(num_classes, num_classes)\n",
    "    # 遍历每对类别，计算其对应的权重\n",
    "    for i in range(num_classes):  # 遍历每个类别\n",
    "        for j in range(num_classes):  # 再次遍历每个类别\n",
    "            if i != j:  # 如果类别不相同\n",
    "                fi = F[i]  # 获取第i个类别的平均脸\n",
    "                fj = F[j]  # 获取第j个类别的平均脸\n",
    "                # 计算第i类别和第j类别平均脸之间的欧氏距离，并将其应用于高斯核函数，计算权重\n",
    "                B[i, j] = np.exp(-np.linalg.norm(fi - fj) ** 2 / t)\n",
    "    np.savetxt(\"B.csv\", B, delimiter=\",\")\n",
    "    # Step 4: 计算E和H矩阵\n",
    "    E = np.diag(np.sum(B, axis=1))\n",
    "    H = E - B\n",
    "    np.savetxt(\"E.csv\", E, delimiter=\",\")\n",
    "    np.savetxt(\"H.csv\", H, delimiter=\",\")\n",
    "    print(\"H:\", H.shape)\n",
    "    # Step 5: 计算目标函数的分母和分子\n",
    "    denominator = np.dot(np.dot(F, H), F.T)\n",
    "    print(\"denominator:\", denominator.shape)\n",
    "    numerator = np.dot(np.dot(X, L), X.T)\n",
    "    print(\"numerator:\", numerator.shape)\n",
    "    # Step 6: 分式\n",
    "    objective_value = numerator / denominator\n",
    "\n",
    "    # Step 7: 求解广义特征值问题的特征值和特征向量\n",
    "    eigenvalues, eigenvectors = eigs(objective_value, k=d+1, which='SR')\n",
    "    sorted_indices = np.argsort(eigenvalues.real)\n",
    "    selected_indices = sorted_indices[1:d + 1]\n",
    "    selected_eigenvectors = eigenvectors.real[:, selected_indices]\n",
    "    return selected_eigenvectors, overall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取第一张灰度图像的大小作为图片形状，如果有图像大小不符合要求则使用以下代码进行缩放\n",
    "# img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# 读取图像数据\n",
    "def read_images(dataset_dir):\n",
    "    data = []  # 存储图像数据的列表\n",
    "    labels = []  # 存储标签的列表\n",
    "    faceshape = [] # 存储图像形状\n",
    "    for class_dir in os.listdir(dataset_dir):  # 遍历数据集文件夹中的文件夹（每个文件夹代表一个类别）\n",
    "        class_path = os.path.join(dataset_dir, class_dir)  # 类别文件夹路径\n",
    "        for file_name in os.listdir(class_path):  # 遍历每个类别文件夹中的图像文件\n",
    "            file_path = os.path.join(class_path, file_name)  # 图像文件路径\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # 读取灰度图像\n",
    "            # 读取第一张灰度图像的大小作为图片形状\n",
    "            faceshape = img.shape\n",
    "            data.append(img.flatten())  # 将图像展平并添加到数据列表中\n",
    "            labels.append(int(class_dir))  # 将类别标签添加到标签列表中\n",
    "    return np.array(data), np.array(labels).reshape(-1, 1), faceshape  # 返回图像数据和标签\n",
    "\n",
    "# 训练集和测试集划分\n",
    "def train_test_split(data, labels, train_test_split_ratio):\n",
    "    train_data, train_labels, test_data, test_labels = [], [], [], []\n",
    "    \n",
    "    # 获取唯一的类别标签\n",
    "    unique_labels = np.unique(labels)\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        # 获取当前类别的样本索引\n",
    "        indices = np.where(labels == label)[0]\n",
    "        num_samples = len(indices)\n",
    "        train_samples = int(num_samples * train_test_split_ratio)\n",
    "        \n",
    "        # 将当前类别的样本分配给训练集和测试集\n",
    "        train_indices = indices[:train_samples]\n",
    "        test_indices = indices[train_samples:]\n",
    "        \n",
    "        train_data.extend(data[train_indices])\n",
    "        train_labels.extend(labels[train_indices])\n",
    "        test_data.extend(data[test_indices])\n",
    "        test_labels.extend(labels[test_indices])\n",
    "    \n",
    "    # 转换为数组格式\n",
    "    train_data = np.array(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_data = np.array(test_data)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像数据形状： (100, 10304)\n",
      "F: (10304, 10)\n",
      "Data形状: (10304, 50)\n",
      "classes_train_data形状: (10304, 5, 10)\n",
      "weight_matrices 形状: (10304, 10304, 10)\n",
      "degree_matrices 形状: (10304, 10304, 10)\n",
      "diagonal_weight_matrices形状: (10, 10304)\n",
      "diagonal_degree_matrices形状: (10, 10304)\n",
      "Laplacian_matrices形状: (10304, 10304, 10)\n",
      "train_data: (50, 10304)\n",
      "H: (10, 10)\n",
      "denominator: (10304, 10304)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10304,5,10) and (10,10304,10304) not aligned: 10 (dim 2) != 10304 (dim 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500000\u001b[39m\n\u001b[0;32m      8\u001b[0m lpp_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 'knn'或'epsilon'\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m dlpp_weight_matrix, overall_mean \u001b[38;5;241m=\u001b[39m \u001b[43mDLPP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlpp_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDLPP权重矩阵形状:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dlpp_weight_matrix\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[71], line 30\u001b[0m, in \u001b[0;36mDLPP\u001b[1;34m(train_data, train_labels, d, lpp_method, k, t)\u001b[0m\n\u001b[0;32m     28\u001b[0m denominator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39mdot(F, H), F\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdenominator:\u001b[39m\u001b[38;5;124m\"\u001b[39m, denominator\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 30\u001b[0m numerator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m, X\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumerator:\u001b[39m\u001b[38;5;124m\"\u001b[39m, numerator\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Step 6: 分式\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10304,5,10) and (10,10304,10304) not aligned: 10 (dim 2) != 10304 (dim 1)"
     ]
    }
   ],
   "source": [
    "dataset = \"attfaces\"\n",
    "data, labels, faceshape = read_images(dataset)\n",
    "print(\"图像数据形状：\", data.shape)\n",
    "train_data, train_labels, test_data, test_labels = train_test_split(data, labels, train_test_split_ratio=0.5)\n",
    "d = 30\n",
    "k = 2500\n",
    "t = 500000\n",
    "lpp_method = 'knn'  # 'knn'或'epsilon'\n",
    "dlpp_weight_matrix, overall_mean = DLPP(train_data, train_labels, d, lpp_method, k, t)\n",
    "print(\"DLPP权重矩阵形状:\", dlpp_weight_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10304,50) and (10304,30) not aligned: 50 (dim 1) != 10304 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[199], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dlpp_eigenfaces \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdlpp_weight_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDLPP特征脸形状：\u001b[39m\u001b[38;5;124m\"\u001b[39m, dlpp_eigenfaces\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m ShowEigenface(dlpp_eigenfaces)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10304,50) and (10304,30) not aligned: 50 (dim 1) != 10304 (dim 0)"
     ]
    }
   ],
   "source": [
    "dlpp_eigenfaces = np.dot(train_data.T, dlpp_weight_matrix)\n",
    "print(\"DLPP特征脸形状：\", dlpp_eigenfaces.shape)\n",
    "ShowEigenface(dlpp_eigenfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(i, faceshape, overall_mean, train_labels, train_data, test_data, dlpp_eigenfaces, dlpp_weight_matrix):\n",
    "    # 计算测试图像的权重向量\n",
    "    #print(\"测试图像形状:\", query.shape)\n",
    "    #print(\"平均人脸形状:\", overall_mean.shape)\n",
    "    #print(\"特征脸形状:\", dlpp_eigenfaces.shape)\n",
    "    query = test_data[i]\n",
    "    query_weight = (dlpp_eigenfaces.T @ (query - overall_mean.flatten()).reshape(-1, 1)).T\n",
    "    # 计算测试图像与数据集中每个人脸的欧氏距离\n",
    "    euclidean_distances = np.linalg.norm(dlpp_weight_matrix - query_weight, axis=0)\n",
    "    # 找到最佳匹配的人脸\n",
    "    best_match_index = np.argmin(euclidean_distances)\n",
    "    #判断是否匹配正确\n",
    "    flag = False\n",
    "    if train_labels[best_match_index] == test_labels[i]:\n",
    "        flag = True\n",
    "    else:\n",
    "        flag = False\n",
    "    # 可视化\n",
    "    '''\n",
    "    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8, 6))\n",
    "    axes[0].imshow(query.reshape(faceshape), cmap=\"gray\")\n",
    "    axes[0].set_title(\"Query Image\")\n",
    "    axes[1].set_xlabel(\"Euclidean Distance: {:.0f}\".format(euclidean_distances[best_match_index]))\n",
    "    axes[1].imshow(train_data[best_match_index].reshape(faceshape), cmap=\"gray\")\n",
    "    axes[1].set_title(\"Best Match\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整参数循环测试并生成结果\n",
    "'''\n",
    "# 定义参数范围\n",
    "d = 30\n",
    "k_range = range(2000, 9001, 500)\n",
    "t_range = range(10000, 1450001, 50000)\n",
    "lpp_method = 'knn'\n",
    "\n",
    "# 检查 CSV 文件是否存在\n",
    "csv_filename = 'outcome.csv'\n",
    "if not os.path.exists(csv_filename):\n",
    "    # 如果文件不存在，创建一个新的 DataFrame\n",
    "    df = pd.DataFrame(columns=['k', 't', 'rate'])\n",
    "else:\n",
    "    # 如果文件存在，读取已有的结果\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "# 遍历参数\n",
    "iteration = 1\n",
    "for k in k_range:\n",
    "    for t in t_range:\n",
    "        # 检查结果是否已经存在\n",
    "        if ((df['k'] == k) & (df['t'] == t)).any():\n",
    "            continue  # 如果结果已经存在，跳过这个参数组合\n",
    "        \n",
    "        # 输出当前参数信息\n",
    "        print(f\"Iteration {iteration}: k={k}, t={t}\")\n",
    "        \n",
    "        # 计算 DLPP\n",
    "        dlpp_weight_matrix, overall_mean = DLPP(train_data, train_labels, d, lpp_method, k, t)\n",
    "        dlpp_eigenfaces = np.dot(train_data.T, dlpp_weight_matrix)\n",
    "        \n",
    "        # 识别率统计\n",
    "        wrong_times = 0\n",
    "        right_times = 0\n",
    "        for i in range(test_data.shape[0]):\n",
    "            flag = test_image(i, faceshape, overall_mean, train_labels, train_data, test_data, dlpp_eigenfaces, dlpp_weight_matrix)\n",
    "            if flag:\n",
    "                right_times += 1\n",
    "            else:\n",
    "                wrong_times += 1\n",
    "        rate = right_times / (right_times + wrong_times)\n",
    "        print(f\"Recognition Rate: {rate}\")\n",
    "        \n",
    "        # 添加结果到 DataFrame\n",
    "        df = pd.concat([df, pd.DataFrame({'k': [k], 't': [t], 'rate': [rate]})], ignore_index=True)\n",
    "\n",
    "        # 保存结果到 CSV 文件\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        \n",
    "        # 增加迭代计数\n",
    "        iteration += 1\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
