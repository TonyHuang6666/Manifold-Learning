{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAPP\n",
    "\n",
    "LPP在选择k个最近邻时存在风险，因为原始数据集中存在噪音。如果错误确定了k个最近邻，整个算法的性能将降低。LAPP采用了一种从粗到细的策略，迭代LPP单元，直到找到满足少量噪声要求的最优子空间。LAPP的伪代码如下：\n",
    "\n",
    "Input：$X= [x_1, x_2, x_3 ... x_m] \\in \\mathbb{R^{m \\times n}}$，最终维度$d$，阈值$\\delta$，最大迭代次数$T$。<br>\n",
    "Output：变换矩阵$A \\in \\mathbb{R^{m \\times d}}$。<br>\n",
    "**1.** 计算相似矩阵S ($x_i$, $x_j$)。<br>\n",
    "&emsp; 对于有监督学习，对于一个有$c$个标签的数据集，我们定义：\n",
    "$$\n",
    "S_{ij} = \\left\\{\n",
    "\\begin{aligned}\n",
    "d(x_i,x_j), & \\quad \\text{if} \\quad x_i \\quad \\text{and} \\quad x_j \\quad \\text{belong to the same class}\\\\\n",
    "0, & \\quad \\text{otherwise}\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "&emsp;其中$d(x_i,x_j)$是$x_i$和$x_j$之间的权重。我们可以用用热核方式来计算权重：\n",
    "$$\n",
    "d(x_i,x_j) = \\exp(-\\frac{||x_i - x_j||^2}{2\\sigma^2})\n",
    "$$\n",
    "&emsp;对于无监督学习，我们可以用以下方式计算相似矩阵：\n",
    "$$\n",
    "S_{ij} = \\left\\{\n",
    "\\begin{aligned}\n",
    "d(x_i,x_j), & \\quad \\text{if} \\quad x_i \\quad \\text{and} \\quad x_j \\quad \\text{are k-nearest neighbors}\\\\\n",
    "0, & \\quad \\text{otherwise}\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "**2.** 根据相似矩阵S计算$S$，$D$和$L$。<br>\n",
    "**3.** 解广义特征值问题，得到$A$。<br>\n",
    "**4.** 迭代 = 0。<br>\n",
    "**5.** __while__ iteration < T:  \n",
    "&emsp;&emsp;&emsp;获取变换后的数据 $X_0 = A^TX$  \n",
    "&emsp;&emsp;&emsp;$A_0 = A$  \n",
    "&emsp;&emsp;&emsp;测量相似矩阵 S ($x_i$, $x_j$)  \n",
    "&emsp;&emsp;&emsp;计算 $S$, $D$ and $L$  \n",
    "&emsp;&emsp;&emsp;解广义特征值问题，得到$A$  \n",
    "&emsp;&emsp;&emsp;__if__ diff($A - A_0$) < $\\delta$:  \n",
    "&emsp;&emsp;&emsp;&emsp;$A = A_0$, __break;__  \n",
    "&emsp;&emsp;&emsp;__end if__  \n",
    "iteration = iteration + 1  \n",
    "__end while__\n",
    "__return__ $A$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse.linalg import eigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_graph(Data, method, k):\n",
    "    # 获取样本点的数量\n",
    "    n = Data.shape[0]\n",
    "    # 初始化k近邻图的邻接矩阵\n",
    "    knn_adjacency_matrix = np.zeros((n, n))  \n",
    "    # 计算欧式距离矩阵\n",
    "    distances = np.sqrt(np.sum((Data[:, None] - Data) ** 2, axis=2))\n",
    "    if method == 'epsilon':\n",
    "        return knn_adjacency_matrix, distances\n",
    "    # 获取每个样本点的最近邻索引\n",
    "    indices = np.argsort(distances, axis=1)[:, 1:k+1]\n",
    "    # 构建k近邻图的权重矩阵\n",
    "    # 遍历每个样本点的最近邻索引\n",
    "    for i in range(n):\n",
    "        knn_adjacency_matrix[i, indices[i]] = 1\n",
    "        knn_adjacency_matrix[indices[i], i] = 1\n",
    "    return knn_adjacency_matrix, distances\n",
    "\n",
    "# 以每个点到其他所有点的平均值作为每个数据点的平均邻域半径\n",
    "def compute_avg_radius(n, distances): \n",
    "    radius = np.zeros(n) # 存储每个数据点的平均邻域半径\n",
    "    for i in range(n): # 计算每个数据点的平均邻域半径\n",
    "        avg_radius = np.mean(distances[i]) # 每个数据点到其他所有点的平均值\n",
    "        radius[i] = avg_radius # 存储每个数据点的平均邻域半径\n",
    "    return radius\n",
    "\n",
    "# 以将距离从小到大排序后的第k个距离作为每个数据点的半径\n",
    "def compute_k_maximun_radius(n, distances, k):\n",
    "    radius = np.zeros(n)\n",
    "    sorted_distances = np.sort(distances, axis=1)  # 对距离矩阵的每一行进行排序\n",
    "    for i in range(n):\n",
    "        # 选取第k个距离作为半径\n",
    "        radius[i] = sorted_distances[i, k]\n",
    "    return radius\n",
    "\n",
    "# 计算k最近邻接矩阵或epsilon邻接矩阵\n",
    "def compute_neighborhood_matrix(Data, method, k):\n",
    "    n = len(Data)\n",
    "    knn_adjacency_matrix, distances = knn_graph(Data, method, k)\n",
    "    if method == 'knn':\n",
    "        return knn_adjacency_matrix, distances\n",
    "    elif method == 'epsilon':\n",
    "        adjacency_matrix = np.zeros((n, n))\n",
    "        radius = compute_k_maximun_radius(n, distances, k)  # 计算每个数据点的邻域半径\n",
    "        for i in range(n):  # 对于数据集中的每个样本点 i\n",
    "            neighbors = np.where(distances[i] <= radius[i])[0]  # 获取epsilon邻域内的样本索引\n",
    "            adjacency_matrix[i, neighbors] = 1\n",
    "            adjacency_matrix[neighbors, i] = 1\n",
    "        return adjacency_matrix, distances\n",
    "\n",
    "# 构建基于热核方法的权重矩阵\n",
    "def construct_weight_matrix(Data, method, k, t):\n",
    "    n = len(Data)\n",
    "    Weight_matrix = np.zeros((n, n))\n",
    "    adjacency_matrix, distances = compute_neighborhood_matrix(Data, method, k)\n",
    "    # 计算相似度矩阵\n",
    "    similarity_matrix = np.exp(-distances ** 2 / t)\n",
    "    # 将相似度矩阵按照邻接矩阵进行筛选，得到需要设置权重的位置\n",
    "    i_indices, j_indices = np.where(adjacency_matrix == 1)\n",
    "    # 设置权重\n",
    "    Weight_matrix[i_indices, j_indices] = similarity_matrix[i_indices, j_indices]\n",
    "    Weight_matrix[j_indices, i_indices] = similarity_matrix[i_indices, j_indices]  # 对称矩阵\n",
    "    # 计算全局相似度\n",
    "    '''\n",
    "    修正权重矩阵的原理是利用全局相似度来修正局部相似度得到的权重矩阵，以使得整个权重矩阵更加平滑和连续。\n",
    "    '''\n",
    "    Weight_matrix += np.exp(-distances ** 2 / t)\n",
    "    return Weight_matrix   \n",
    "\n",
    "\n",
    "def LPP(Data, d, method, k, t):\n",
    "    # Step 1: 计算权重矩阵\n",
    "    Weight_matrix = construct_weight_matrix(Data, method, k, t)\n",
    "    # Step 2: 计算度矩阵和拉普拉斯矩阵\n",
    "    Degree_matrix = np.diag(np.sum(Weight_matrix, axis=1))\n",
    "    Laplacian_matrix = Degree_matrix - Weight_matrix\n",
    "    # Step 3: 进行特征映射\n",
    "    eigenvalues, eigenvectors = eigs(Laplacian_matrix, k=d+1, which='SR')\n",
    "    sorted_indices = np.argsort(eigenvalues.real)\n",
    "    selected_indices = sorted_indices[1:d + 1]\n",
    "    selected_eigenvectors = eigenvectors.real[:, selected_indices]\n",
    "    return selected_eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAPP算法(无监督学习)\n",
    "def LAPP(Data, d, method, k, t, max_iterations, delta):\n",
    "    A = LPP(Data, d, method, k, t)  # 使用LPP初始化变换矩阵A\n",
    "    for _ in range(max_iterations):\n",
    "        A_old = A.copy()\n",
    "        # 根据当前的变换矩阵A计算新的权重矩阵\n",
    "        Weight_matrix = construct_weight_matrix(Data @ A, method, k, t)\n",
    "        # 更新拉普拉斯矩阵\n",
    "        Degree_matrix = np.diag(np.sum(Weight_matrix, axis=1))\n",
    "        Laplacian_matrix = Degree_matrix - Weight_matrix\n",
    "        # 解广义特征值问题，得到新的变换矩阵A\n",
    "        eigenvalues, eigenvectors = eigs(Laplacian_matrix, k=d+1, which='SR')\n",
    "        sorted_indices = np.argsort(eigenvalues.real)\n",
    "        selected_indices = sorted_indices[1:d + 1]\n",
    "        A = eigenvectors.real[:, selected_indices]\n",
    "        # 检查迭代是否收敛\n",
    "        diff = np.linalg.norm(A - A_old)\n",
    "        if diff < delta:\n",
    "            break\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(dataset_dir, target_size=(32, 32)):\n",
    "    data = []  # 存储图像数据的列表\n",
    "    labels = []  # 存储标签的列表\n",
    "    faceshape = [] # 存储图像形状\n",
    "    for class_dir in os.listdir(dataset_dir):  # 遍历数据集文件夹中的文件夹（每个文件夹代表一个类别）\n",
    "        class_path = os.path.join(dataset_dir, class_dir)  # 类别文件夹路径\n",
    "        for file_name in os.listdir(class_path):  # 遍历每个类别文件夹中的图像文件\n",
    "            file_path = os.path.join(class_path, file_name)  # 图像文件路径\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # 读取灰度图像\n",
    "            # 缩放图像至目标尺寸\n",
    "            img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "            # 读取第一张灰度图像的大小作为图片形状\n",
    "            faceshape = img.shape\n",
    "            data.append(img.flatten())  # 将图像展平并添加到数据列表中\n",
    "            labels.append(int(class_dir))  # 将类别标签添加到标签列表中\n",
    "    return np.array(data), np.array(labels).reshape(-1, 1), faceshape  # 返回图像数据和标签\n",
    "\n",
    "# 训练集和测试集划分\n",
    "def train_test_split(data, labels, train_test_split_ratio):\n",
    "    num_samples = data.shape[0]  # 总样本数\n",
    "    train_samples = int(num_samples * train_test_split_ratio)  # 训练集样本数\n",
    "    \n",
    "    # 洗牌算法打乱数据集\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    data = data[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    train_data = data[:train_samples]\n",
    "    train_labels = labels[:train_samples]\n",
    "    test_data = data[train_samples:]\n",
    "    test_labels = labels[train_samples:]\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(i, faceshape, overall_mean, train_labels, test_labels, train_data, test_data, lpp_eigenfaces, lpp_weight_matrix):\n",
    "    # 计算测试图像的权重向量\n",
    "    #print(\"测试图像形状:\", query.shape)\n",
    "    #print(\"平均人脸形状:\", overall_mean.shape)\n",
    "    #print(\"特征脸形状:\", dlpp_eigenfaces.shape)\n",
    "    query = test_data[i]\n",
    "    query_weight = (lpp_eigenfaces.T @ (query - overall_mean.flatten()).reshape(-1, 1))\n",
    "    # 计算测试图像与数据集中每个人脸的欧氏距离\n",
    "    euclidean_distances = np.linalg.norm(lpp_weight_matrix - query_weight, axis=0)\n",
    "    # 找到最佳匹配的人脸\n",
    "    best_match_index = np.argmin(euclidean_distances)\n",
    "    #判断是否匹配正确\n",
    "    flag = False\n",
    "    if train_labels[best_match_index] == test_labels[i]:\n",
    "        flag = True\n",
    "    else:\n",
    "        flag = False\n",
    "    \"\"\"\n",
    "    # 可视化\n",
    "    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8, 6))\n",
    "    axes[0].imshow(query.reshape(faceshape), cmap=\"gray\")\n",
    "    axes[0].set_title(\"Query Image\")\n",
    "    axes[1].set_xlabel(\"Euclidean Distance: {:.0f}\".format(euclidean_distances[best_match_index]))\n",
    "    axes[1].imshow(train_data[best_match_index].reshape(faceshape), cmap=\"gray\")\n",
    "    axes[1].set_title(\"Best Match\")\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowEigenface(eigenfaces, faceshape):\n",
    "    # 显示前16个特征脸\n",
    "    fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(8, 10))\n",
    "    for i in range(16):\n",
    "        axes[i%4][i//4].imshow(eigenfaces[:, i].reshape(faceshape), cmap=\"gray\")\n",
    "    #print(\"显示特征脸\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人脸图像形状: (32, 32)\n",
      "类别数量: 400\n",
      "图像数量: 400\n"
     ]
    }
   ],
   "source": [
    "# 读取人脸图像\n",
    "faces, classes, faceshape = read_images(\"ORL\")  # 读取图像数据和标签\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = train_test_split(faces, classes, 0.5)  # 划分训练集和测试集\n",
    "# 打印一些细节\n",
    "print(\"人脸图像形状:\", faceshape)\n",
    "print(\"类别数量:\", len(classes))\n",
    "print(\"图像数量:\", len(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状： (1024, 200)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (70,1024) (1024,1024) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 24\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m训练集形状：\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#from lpproj import LocalityPreservingProjection\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#lpp = LocalityPreservingProjection(n_neighbors=n_neighbors, n_components=n_components)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#lpp.fit(train_data)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#lpp_eigenfaces = lpp.transform(train_data)\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m lpp_eigenfaces \u001b[38;5;241m=\u001b[39m \u001b[43mLAPP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m特征脸形状:\u001b[39m\u001b[38;5;124m\"\u001b[39m, lpp_eigenfaces\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     27\u001b[0m overall_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(train_data , axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[84], line 34\u001b[0m, in \u001b[0;36mLAPP\u001b[1;34m(Data, d, delta, T)\u001b[0m\n\u001b[0;32m     31\u001b[0m S \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m@\u001b[39m S \u001b[38;5;241m@\u001b[39m A\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 检查迭代是否收敛\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[43mA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mA_old\u001b[49m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff \u001b[38;5;241m<\u001b[39m delta:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (70,1024) (1024,1024) "
     ]
    }
   ],
   "source": [
    "# 应用LPP并选择前K个主成分作为特征脸\n",
    "\n",
    "d = 70\n",
    "k = 135\n",
    "t = 87250\n",
    "method = 'knn'\n",
    "delta = 1e-6\n",
    "max_iterations = 5\n",
    "\"\"\"\n",
    "d = 70\n",
    "k = 450\n",
    "t = 50000\n",
    "method = 'epsilon'\n",
    "\"\"\"\n",
    "train_data = train_data.T\n",
    "print(\"训练集形状：\", train_data.shape)\n",
    "#from lpproj import LocalityPreservingProjection\n",
    "#lpp = LocalityPreservingProjection(n_neighbors=n_neighbors, n_components=n_components)\n",
    "#lpp.fit(train_data)\n",
    "#lpp_eigenfaces = lpp.transform(train_data)\n",
    "\n",
    "\n",
    "\n",
    "lpp_eigenfaces = LAPP(train_data, d, delta, max_iterations)\n",
    "print(\"特征脸形状:\", lpp_eigenfaces.shape)\n",
    "\n",
    "overall_mean = np.mean(train_data , axis=1).reshape(-1, 1)\n",
    "print(\"平均人脸形状:\", overall_mean.shape)\n",
    "\n",
    "lpp_weight_matrix = lpp_eigenfaces.T @ (train_data-overall_mean) \n",
    "print(\"权重矩阵形状:\", lpp_weight_matrix.shape)\n",
    "\n",
    "ShowEigenface(lpp_eigenfaces, faceshape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition Rate: 0.87\n"
     ]
    }
   ],
   "source": [
    "# 识别率统计\n",
    "wrong_times = 0\n",
    "right_times = 0\n",
    "for i in range(test_data.shape[0]):\n",
    "    flag = test_image(i, faceshape, overall_mean, train_labels, test_labels, train_data, test_data, lpp_eigenfaces, lpp_weight_matrix)\n",
    "    if flag:\n",
    "                right_times += 1\n",
    "    else:\n",
    "        wrong_times += 1\n",
    "rate = right_times / test_data.shape[0]\n",
    "print(f\"Recognition Rate: {rate}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
